{"version":3,"file":"index.js","sources":["../src/index.ts"],"sourcesContent":["import data from './dataset.json';\n\ntype Result = {\n  best: string;\n  sortedLangs: string[];\n  probabilities: Record<string, number>;\n};\n\n/**\n * Normalize text to standardize it for comparison, preserving accents and diacritics.\n * @param text\n * @returns\n */\nfunction normalize(text: string): string {\n  return text.normalize('NFD').toLowerCase();\n}\n\n/**\n * Tokenize the text to only get the words, considering normalized text.\n * @param text\n * @returns\n */\nfunction tokenize(text: string): string[] {\n  return normalize(text)\n    .replace(/[^a-z\\u00C0-\\u00FF]+/gi, ' ') // Remove not letter/accent char\n    .trim()\n    .split(/\\s+/);\n}\n\n/**\n * Give the list of supported languages in ISO639-1 format.\n * @returns\n */\nfunction langySupportedLanguages(): string[] {\n  return Object.keys(data);\n}\n\n/**\n * Calculate the weight for each word based on its frequency across languages.\n * @param tokens\n * @param dataEntries\n * @returns\n */\nfunction calculateWordWeights(\n  tokens: string[],\n  dataEntries: [string, string[]][]\n): Record<string, Record<string, number>> {\n  const wordWeights: Record<string, Record<string, number>> = {};\n  const wordCounts: Record<string, number> = {};\n\n  // Count occurrences of each word in each language\n  for (const token of tokens) {\n    for (const [lang, words] of dataEntries) {\n      if (words.includes(token)) {\n        if (!wordWeights[token]) {\n          wordWeights[token] = {};\n        }\n        wordWeights[token][lang] = (wordWeights[token][lang] || 0) + 1;\n        wordCounts[token] = (wordCounts[token] || 0) + 1;\n      }\n    }\n  }\n\n  // Normalize weights by the total number of languages a word appears in\n  for (const [word, counts] of Object.entries(wordWeights)) {\n    const totalAppearance = Object.values(counts).reduce((sum, count) => sum + count, 0);\n    for (const lang in counts) {\n      wordWeights[word][lang] = counts[lang] / totalAppearance;\n    }\n  }\n\n  return wordWeights;\n}\n\n/**\n * Give a sorted list of the detected language from a text.\n * @param text\n * @returns\n */\nfunction langy(text: string): Result {\n  const tokens = tokenize(text);\n  const dataEntries = Object.entries(data);\n  const wordWeights = calculateWordWeights(tokens, dataEntries);\n  const result: Result = {\n    best: '',\n    sortedLangs: [],\n    probabilities: {}\n  };\n\n  for (const token of tokens) {\n    if (wordWeights[token]) {\n      for (const [lang, weight] of Object.entries(wordWeights[token])) {\n        result.probabilities[lang] = (result.probabilities[lang] || 0) + weight;\n      }\n    }\n  }\n\n  let bestLang = '';\n  let bestScore = -Infinity;\n\n  // Normalize probabilities and find the best language\n  const totalWeights = Object.values(result.probabilities).reduce((sum, prob) => sum + prob, 0);\n  for (const lang in result.probabilities) {\n    const proba = result.probabilities[lang] / totalWeights;\n    result.probabilities[lang] = proba;\n\n    if (proba > bestScore) {\n      bestLang = lang;\n      bestScore = proba;\n    }\n  }\n\n  result.best = bestLang;\n  result.sortedLangs = Object.keys(result.probabilities).sort(\n    (a, b) => result.probabilities[b] - result.probabilities[a]\n  );\n\n  return result;\n}\n\nexport { langy, langySupportedLanguages };\n"],"names":["text","tokens","normalize","toLowerCase","replace","trim","split","tokenize","wordWeights","dataEntries","token","lang","words","includes","word","counts","Object","entries","totalAppearance","values","reduce","sum","count","calculateWordWeights","data","result","best","sortedLangs","probabilities","weight","bestLang","bestScore","Infinity","totalWeights","prob","proba","keys","sort","a","b"],"mappings":"o49jHA+EA,SAAeA,GACb,MAAMC,EA1DR,SAAkBD,GAChB,OAVF,SAAmBA,GACjB,OAAOA,EAAKE,UAAU,OAAOC,aAC/B,CAQSD,CAAUF,GACdI,QAAQ,yBAA0B,KAClCC,OACAC,MAAM,MACX,CAqDiBC,CAASP,GAElBQ,EAvCR,SACEP,EACAQ,GAEA,MAAMD,EAAsD,CAAA,EAI5D,IAAK,MAAME,KAAST,EAClB,IAAK,MAAOU,EAAMC,KAAUH,EACtBG,EAAMC,SAASH,KACZF,EAAYE,KACfF,EAAYE,GAAS,IAEvBF,EAAYE,GAAOC,IAASH,EAAYE,GAAOC,IAAS,GAAK,GAOnE,IAAK,MAAOG,EAAMC,KAAWC,OAAOC,QAAQT,GAAc,CACxD,MAAMU,EAAkBF,OAAOG,OAAOJ,GAAQK,QAAO,CAACC,EAAKC,IAAUD,EAAMC,GAAO,GAClF,IAAK,MAAMX,KAAQI,EACjBP,EAAYM,GAAMH,GAAQI,EAAOJ,GAAQO,CAE5C,CAED,OAAOV,CACT,CAUsBe,CAAqBtB,EADrBe,OAAOC,QAAQO,IAE7BC,EAAiB,CACrBC,KAAM,GACNC,YAAa,GACbC,cAAe,CAAE,GAGnB,IAAK,MAAMlB,KAAST,EAClB,GAAIO,EAAYE,GACd,IAAK,MAAOC,EAAMkB,KAAWb,OAAOC,QAAQT,EAAYE,IACtDe,EAAOG,cAAcjB,IAASc,EAAOG,cAAcjB,IAAS,GAAKkB,EAKvE,IAAIC,EAAW,GACXC,GAAaC,IAGjB,MAAMC,EAAejB,OAAOG,OAAOM,EAAOG,eAAeR,QAAO,CAACC,EAAKa,IAASb,EAAMa,GAAM,GAC3F,IAAK,MAAMvB,KAAQc,EAAOG,cAAe,CACvC,MAAMO,EAAQV,EAAOG,cAAcjB,GAAQsB,EAC3CR,EAAOG,cAAcjB,GAAQwB,EAEzBA,EAAQJ,IACVD,EAAWnB,EACXoB,EAAYI,EAEf,CAOD,OALAV,EAAOC,KAAOI,EACdL,EAAOE,YAAcX,OAAOoB,KAAKX,EAAOG,eAAeS,MACrD,CAACC,EAAGC,IAAMd,EAAOG,cAAcW,GAAKd,EAAOG,cAAcU,KAGpDb,CACT,4BArFA,WACE,OAAOT,OAAOoB,KAAKZ,EACrB"}