{"version":3,"file":"index.js","sources":["../src/index.ts"],"sourcesContent":["import data from './dataset.json';\r\n\r\ntype Result = {\r\n  best: string;\r\n  sortedLangs: string[];\r\n  probabilities: Record<string, number>;\r\n};\r\n\r\n/**\r\n * Normalize text to standardize it for comparison, preserving accents and diacritics.\r\n * @param text\r\n * @returns\r\n */\r\nfunction normalize(text: string): string {\r\n  return text.normalize('NFD').toLowerCase();\r\n}\r\n\r\n/**\r\n * Tokenize the text to only get the words, considering normalized text.\r\n * @param text\r\n * @returns\r\n */\r\nfunction tokenize(text: string): string[] {\r\n  return normalize(text)\r\n    .replace(/[^a-z\\u00C0-\\u00FF]+/gi, ' ') // Remove not letter/accent char\r\n    .trim()\r\n    .split(/\\s+/);\r\n}\r\n\r\n/**\r\n * Give the list of supported languages in ISO639-1 format.\r\n * @returns\r\n */\r\nfunction langySupportedLanguages(): string[] {\r\n  return Object.keys(data);\r\n}\r\n\r\n/**\r\n * Calculate the weight for each word based on its frequency across languages.\r\n * @param tokens\r\n * @param dataEntries\r\n * @returns\r\n */\r\nfunction calculateWordWeights(\r\n  tokens: string[],\r\n  dataEntries: [string, string[]][]\r\n): Record<string, Record<string, number>> {\r\n  const wordWeights: Record<string, Record<string, number>> = {};\r\n  const wordCounts: Record<string, number> = {};\r\n\r\n  // Count occurrences of each word in each language\r\n  for (const token of tokens) {\r\n    for (const [lang, words] of dataEntries) {\r\n      if (words.includes(token)) {\r\n        if (!wordWeights[token]) {\r\n          wordWeights[token] = {};\r\n        }\r\n        wordWeights[token][lang] = (wordWeights[token][lang] || 0) + 1;\r\n        wordCounts[token] = (wordCounts[token] || 0) + 1;\r\n      }\r\n    }\r\n  }\r\n\r\n  // Normalize weights by the total number of languages a word appears in\r\n  for (const [word, counts] of Object.entries(wordWeights)) {\r\n    const totalAppearance = Object.values(counts).reduce((sum, count) => sum + count, 0);\r\n    for (const lang in counts) {\r\n      wordWeights[word][lang] = counts[lang] / totalAppearance;\r\n    }\r\n  }\r\n\r\n  return wordWeights;\r\n}\r\n\r\n/**\r\n * Give a sorted list of the detected language from a text.\r\n * @param text\r\n * @returns\r\n */\r\nfunction langy(text: string): Result {\r\n  const tokens = tokenize(text);\r\n  const dataEntries = Object.entries(data);\r\n  const wordWeights = calculateWordWeights(tokens, dataEntries);\r\n  const result: Result = {\r\n    best: '',\r\n    sortedLangs: [],\r\n    probabilities: {}\r\n  };\r\n\r\n  for (const token of tokens) {\r\n    if (wordWeights[token]) {\r\n      for (const [lang, weight] of Object.entries(wordWeights[token])) {\r\n        result.probabilities[lang] = (result.probabilities[lang] || 0) + weight;\r\n      }\r\n    }\r\n  }\r\n\r\n  let bestLang = '';\r\n  let bestScore = -Infinity;\r\n\r\n  // Normalize probabilities and find the best language\r\n  const totalWeights = Object.values(result.probabilities).reduce((sum, prob) => sum + prob, 0);\r\n  for (const lang in result.probabilities) {\r\n    const proba = result.probabilities[lang] / totalWeights;\r\n    result.probabilities[lang] = proba;\r\n\r\n    if (proba > bestScore) {\r\n      bestLang = lang;\r\n      bestScore = proba;\r\n    }\r\n  }\r\n\r\n  result.best = bestLang;\r\n  result.sortedLangs = Object.keys(result.probabilities).sort(\r\n    (a, b) => result.probabilities[b] - result.probabilities[a]\r\n  );\r\n\r\n  return result;\r\n}\r\n\r\nexport { langy, langySupportedLanguages };\r\n"],"names":["text","tokens","normalize","toLowerCase","replace","trim","split","tokenize","wordWeights","dataEntries","token","lang","words","includes","word","counts","Object","entries","totalAppearance","values","reduce","sum","count","calculateWordWeights","data","result","best","sortedLangs","probabilities","weight","bestLang","bestScore","Infinity","totalWeights","prob","proba","keys","sort","a","b"],"mappings":"o49jHA+EA,SAAeA,GACb,MAAMC,EA1DR,SAAkBD,GAChB,OAVF,SAAmBA,GACjB,OAAOA,EAAKE,UAAU,OAAOC,aAC/B,CAQSD,CAAUF,GACdI,QAAQ,yBAA0B,KAClCC,OACAC,MAAM,MACX,CAqDiBC,CAASP,GAElBQ,EAvCR,SACEP,EACAQ,GAEA,MAAMD,EAAsD,CAAA,EAI5D,IAAK,MAAME,KAAST,EAClB,IAAK,MAAOU,EAAMC,KAAUH,EACtBG,EAAMC,SAASH,KACZF,EAAYE,KACfF,EAAYE,GAAS,IAEvBF,EAAYE,GAAOC,IAASH,EAAYE,GAAOC,IAAS,GAAK,GAOnE,IAAK,MAAOG,EAAMC,KAAWC,OAAOC,QAAQT,GAAc,CACxD,MAAMU,EAAkBF,OAAOG,OAAOJ,GAAQK,QAAO,CAACC,EAAKC,IAAUD,EAAMC,GAAO,GAClF,IAAK,MAAMX,KAAQI,EACjBP,EAAYM,GAAMH,GAAQI,EAAOJ,GAAQO,CAE5C,CAED,OAAOV,CACT,CAUsBe,CAAqBtB,EADrBe,OAAOC,QAAQO,IAE7BC,EAAiB,CACrBC,KAAM,GACNC,YAAa,GACbC,cAAe,CAAE,GAGnB,IAAK,MAAMlB,KAAST,EAClB,GAAIO,EAAYE,GACd,IAAK,MAAOC,EAAMkB,KAAWb,OAAOC,QAAQT,EAAYE,IACtDe,EAAOG,cAAcjB,IAASc,EAAOG,cAAcjB,IAAS,GAAKkB,EAKvE,IAAIC,EAAW,GACXC,GAAaC,IAGjB,MAAMC,EAAejB,OAAOG,OAAOM,EAAOG,eAAeR,QAAO,CAACC,EAAKa,IAASb,EAAMa,GAAM,GAC3F,IAAK,MAAMvB,KAAQc,EAAOG,cAAe,CACvC,MAAMO,EAAQV,EAAOG,cAAcjB,GAAQsB,EAC3CR,EAAOG,cAAcjB,GAAQwB,EAEzBA,EAAQJ,IACVD,EAAWnB,EACXoB,EAAYI,EAEf,CAOD,OALAV,EAAOC,KAAOI,EACdL,EAAOE,YAAcX,OAAOoB,KAAKX,EAAOG,eAAeS,MACrD,CAACC,EAAGC,IAAMd,EAAOG,cAAcW,GAAKd,EAAOG,cAAcU,KAGpDb,CACT,4BArFA,WACE,OAAOT,OAAOoB,KAAKZ,EACrB"}